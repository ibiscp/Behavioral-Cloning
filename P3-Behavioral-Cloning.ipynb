{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Behavioral Clonning\n",
    "The goal of the following project is to develop a deep neural network to learn how to drive a simulated car.\n",
    "\n",
    "## Load Images File\n",
    "\n",
    "This file pre process the data image and CSV generated by the simulator. Udacity provided a data package, which can be download in [this link](https://d17h27t6h515a5.cloudfront.net/topher/2016/December/584f6edd_data/data.zip) containing the following files:\n",
    "* Folder with 8.036 simulation images, showing the center, left and right camera view of the road, totalizing 24.108 images\n",
    "* File <em>driving\\_log.csv</em> containing a list describing all the images\n",
    "    * Center image path\n",
    "    * Left image path\n",
    "    * Right image path\n",
    "    * Steering angle\n",
    "    * Throttle\n",
    "    * Brake\n",
    "    * Speed\n",
    "\n",
    "Bellow are some examples of the images provided by Udacity and how it is shown in the _csv_ file:\n",
    "\n",
    "\n",
    "IMG/center_2016_12_01_13_30_48_287.jpg, IMG/left_2016_12_01_13_30_48_287.jpg, IMG/right_2016_12_01_13_30_48_287.jpg, 0, 0, 0, 22.14829\n",
    "\n",
    "* Center image path - IMG/center_2016_12_01_13_30_48_287.jpg\n",
    "* Left image path - IMG/left_2016_12_01_13_30_48_287.jpg\n",
    "* Right image path - IMG/right_2016_12_01_13_30_48_287.jpg\n",
    "* Steering angle - 0\n",
    "* Throttle - 0\n",
    "* Brake - 0\n",
    "* Speed - 22.14829\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images mapped with 8043 examples\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nof8PgnhzxQxVsEwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xc55f1cf6d8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "'''\n",
    "    Read driving_log.csv and save it in a vector with the following configuration:\n",
    "        * Image path\n",
    "        * Steering angle\n",
    "        * Throttle\n",
    "        * Brake\n",
    "        * Speed\n",
    "'''\n",
    "\n",
    "import csv\n",
    "import numpy as np\n",
    "\n",
    "list_images = list()\n",
    "\n",
    "# The following value is added and subtracted from the steering angle for the images of the right and left side of the car\n",
    "offset = 0.25\n",
    "\n",
    "import random\n",
    "bias = 0.5\n",
    "\n",
    "with open('data\\driving_log.csv', 'r') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    next(reader)\n",
    "    for row in reader:\n",
    "        steering = float(row[3])\n",
    "        throttle = float(row[4])\n",
    "        brake = float(row[5])\n",
    "        speed = float(row[6])\n",
    "\n",
    "#         if (steering == 0):\n",
    "#             if (np.random.rand() > 0.9999):\n",
    "#                 # Center image\n",
    "#                 list_images.append([row[0].replace(\" \", \"\"), steering, throttle, brake, speed])\n",
    "#         else:\n",
    "#         if (steering != 0):\n",
    "#             if (np.random.rand() > 0.0):\n",
    "        if np.random.rand() > 0.0:\n",
    "            steering_thresh = np.random.rand()\n",
    "            if (abs(steering) + bias) < steering_thresh:\n",
    "                pass # drop this sample\n",
    "            else:\n",
    "                if (steering == 0):\n",
    "                    if (np.random.rand() > 0.85):\n",
    "                        # Center image\n",
    "                        list_images.append([row[0].replace(\" \", \"\"), steering, throttle, brake, speed])\n",
    "                        # Left image\n",
    "                        list_images.append([row[1].replace(\" \", \"\"), steering + offset, throttle, brake, speed])\n",
    "                        # Right image\n",
    "                        list_images.append([row[2].replace(\" \", \"\"), steering - offset, throttle, brake, speed])\n",
    "                else:\n",
    "                    # Center image\n",
    "                    list_images.append([row[0].replace(\" \", \"\"), steering, throttle, brake, speed])\n",
    "                    # Left image\n",
    "                    list_images.append([row[1].replace(\" \", \"\"), steering + offset, throttle, brake, speed])\n",
    "                    # Right image\n",
    "                    list_images.append([row[2].replace(\" \", \"\"), steering - offset, throttle, brake, speed])\n",
    "        \n",
    "print('Images mapped with {} examples'.format(len(list_images)))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "histogram = [x[1] for x in list_images]\n",
    "\n",
    "plt.hist(histogram, bins = 40, facecolor='blue');\n",
    "plt.xlabel('Steering angle');\n",
    "plt.ylabel('Frequency');\n",
    "plt.title('Histogram of recorded steering angles');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ploting histogram\n",
    "In order to analyze the angles distribution of our dataset, a histogram is plotted bellow. Here is possible to see that a higher number of small steerings is presented in the dataset, with a higher number of three especific angle band."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Augmentation\n",
    "In order to generate more data without the necessity of collectiong it, it is possible to apply some transformations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "%matplotlib inline\n",
    "\n",
    "def plot_image_prob(image):\n",
    "    fig = plt.figure(facecolor=\"white\")\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.imshow(image, vmin=0, vmax=255)\n",
    "    plt.axis('off')\n",
    "    ax.axis('tight')\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    plt.show()\n",
    "\n",
    "def flip_image(img, steering):\n",
    "    if random.randint(0, 1):\n",
    "        return cv2.flip(img, 1), -steering\n",
    "    else:\n",
    "        return img, steering\n",
    "    \n",
    "def brightness_image(img, steering):\n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    hsv[:,:,2] = hsv[:,:,2] * random.uniform(0.3, 1.2)\n",
    "    return cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR), steering\n",
    "\n",
    "def rotate_image(img, steering):\n",
    "    rows,cols,channel = img.shape\n",
    "    M = cv2.getRotationMatrix2D((cols/2,rows/2), random.uniform(-5, 5), 1)\n",
    "    return cv2.warpAffine(img,M,(cols,rows)), steering\n",
    "\n",
    "def cut_image(img):\n",
    "    rows,cols,channel = img.shape\n",
    "    top = int(.4 * rows)\n",
    "    botton = int(.85 * rows)\n",
    "    border = int(.05 * cols)\n",
    "    return img[top:botton, border:cols-border, :]\n",
    "\n",
    "def translate_image(img, steering, horz_range=30, vert_range=5):\n",
    "    rows, cols, chs = img.shape\n",
    "    tx = np.random.randint(-horz_range, horz_range+1)\n",
    "    ty = np.random.randint(-vert_range, vert_range+1)\n",
    "    steering = steering + tx * 0.004 # mul by steering angle units per pixel\n",
    "    tr_M = np.float32([[1,0,tx], [0,1,ty]])\n",
    "    img = cv2.warpAffine(img, tr_M, (cols,rows), borderMode=1)\n",
    "    return img, steering\n",
    "\n",
    "# example = list_images[random.randint(0,len(list_images))]\n",
    "# image = Image.open(\"data/\" + example[0])\n",
    "# print(\"Original shape: {}\".format(image.size))\n",
    "# new_image, new_steering = rotate_image(np.copy(image), example[1])\n",
    "# cutted_image = cut_image(new_image)\n",
    "# print(\"New shape: {}\".format(cutted_image.shape))\n",
    "# print(\"Old steering: {}\".format(example[1]))\n",
    "# print(\"New steering: {}\".format(new_steering))\n",
    "# plot_image_prob(image)\n",
    "# plot_image_prob(new_image)\n",
    "# plot_image_prob(cutted_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data\n",
    "The data will not be entirely loaded to the memory because the dataset is too big, so a function *load_data* is created in order to load the data as it is needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import progressbar\n",
    "import pickle\n",
    "import os.path\n",
    "\n",
    "def load_data(list_images):\n",
    "    # Placeholders for the images and labels from web\n",
    "    X = np.empty(shape = [1, 320, 160, 3], dtype = np.uint8)\n",
    "    y = np.empty(shape = [1], dtype = np.float32)\n",
    "    \n",
    "    bar = progressbar.ProgressBar()\n",
    "    for i in bar(range(len(list_images))):\n",
    "        image = Image.open(\"data/\" + list_images[i][0])\n",
    "        steering = list_images[i][1]\n",
    "\n",
    "        X = np.vstack([X, np.reshape(image, [1, 320, 160, 3])])\n",
    "        y = np.vstack([y, steering])\n",
    "\n",
    "        image, steering = flip_image(np.copy(image), steering)\n",
    "\n",
    "        X = np.vstack([X, np.reshape(image, [1, 320, 160, 3])])\n",
    "        y = np.vstack([y, steering])\n",
    "    \n",
    "    # Get rid of the first empty row\n",
    "    X = X[1:, :, :, :]\n",
    "    y = y[1:]\n",
    "\n",
    "    return X, y\n",
    "\n",
    "def load_data_batch(list_images, indices):\n",
    "    # Placeholders for the images and labels from web\n",
    "    X = np.empty(shape = [1, 320, 160, 3], dtype = np.uint8)\n",
    "    y = np.empty(shape = [1], dtype = np.float32)\n",
    "\n",
    "    for i in indices:\n",
    "        image = Image.open(\"data/\" + list_images[i][0])\n",
    "        steering = list_images[i][1]\n",
    "\n",
    "        X = np.vstack([X, np.reshape(image, [1, 320, 160, 3])])\n",
    "        y = np.vstack([y, steering])\n",
    "    \n",
    "    # Get rid of the first empty row\n",
    "    X = X[1:, :, :, :]\n",
    "    y = y[1:]\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file = \"data.p\" # File name\n",
    "\n",
    "# If file exists read, if not, create file\n",
    "if (os.path.isfile(file)):\n",
    "    with open(file, mode='rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    \n",
    "    X, y = data['images'], data['steering']\n",
    "    print(\"File already in disk! Images loaded\\n\")\n",
    "else:\n",
    "    # print(\"Creating image file\")\n",
    "    X, y = load_data(list_images)\n",
    "\n",
    "    # Save file to \n",
    "    d = {'images': X, 'steering': y}\n",
    "\n",
    "    output = open('data.p', 'wb')\n",
    "    pickle.dump(d, output)\n",
    "    output.close()\n",
    "    \n",
    "# Convert data to float\n",
    "X = X.astype('float32')\n",
    "y = y.astype('float32')\n",
    "\n",
    "print(\"X_train shape =\", X.shape)\n",
    "print(\"y_train shape =\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.hist(y, bins = 40, facecolor='blue');\n",
    "plt.xlabel('Steering angle');\n",
    "plt.ylabel('Frequency');\n",
    "plt.title('Histogram of recorded steering angles');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural network implementation\n",
    "Bellow will be implemented the network network, which is based on the paper released by NVIDIA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "convolution2d_1 (Convolution2D)  (None, 64, 64, 24)    1824        convolution2d_input_1[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "activation_1 (Activation)        (None, 64, 64, 24)    0           convolution2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_1 (MaxPooling2D)    (None, 32, 32, 24)    0           activation_1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_2 (Convolution2D)  (None, 28, 28, 36)    21636       maxpooling2d_1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_2 (Activation)        (None, 28, 28, 36)    0           convolution2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_2 (MaxPooling2D)    (None, 14, 14, 36)    0           activation_2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_3 (Convolution2D)  (None, 10, 10, 48)    43248       maxpooling2d_2[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_3 (Activation)        (None, 10, 10, 48)    0           convolution2d_3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_3 (MaxPooling2D)    (None, 5, 5, 48)      0           activation_3[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_4 (Convolution2D)  (None, 3, 3, 64)      27712       maxpooling2d_3[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_4 (Activation)        (None, 3, 3, 64)      0           convolution2d_4[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_5 (Convolution2D)  (None, 1, 1, 64)      36928       activation_4[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "activation_5 (Activation)        (None, 1, 1, 64)      0           convolution2d_5[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (None, 64)            0           activation_5[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 100)           6500        flatten_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 100)           0           dense_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "activation_6 (Activation)        (None, 100)           0           dropout_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 50)            5050        activation_6[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)              (None, 50)            0           dense_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "activation_7 (Activation)        (None, 50)            0           dropout_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_3 (Dense)                  (None, 10)            510         activation_7[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)              (None, 10)            0           dense_3[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "activation_8 (Activation)        (None, 10)            0           dropout_3[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_4 (Dense)                  (None, 1)             11          activation_8[0][0]               \n",
      "====================================================================================================\n",
      "Total params: 143,419\n",
      "Trainable params: 143,419\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Convolution2D, Flatten, Activation, MaxPooling2D, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# Layer 1: Input: 72 x 288 x 3 - Output: 35 x 143 x 24\n",
    "model.add(Convolution2D(24, 5, 5, input_shape=(64, 64, 3), border_mode='same', init='normal'))\n",
    "model.add(Activation('elu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "#model.add(BatchNormalization())\n",
    "\n",
    "# Layer 2: Input: 72 x 288 x 3 - Output: 35 x 143 x 24\n",
    "model.add(Convolution2D(36, 5, 5, init='normal'))\n",
    "model.add(Activation('elu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "#model.add(BatchNormalization())\n",
    "\n",
    "# Layer 3: Input: 72 x 288 x 3 - Output: 35 x 143 x 24\n",
    "model.add(Convolution2D(48, 5, 5, init='normal'))\n",
    "model.add(Activation('elu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "#model.add(BatchNormalization())\n",
    "\n",
    "# Layer 4: Input: 72 x 288 x 3 - Output: 35 x 143 x 24\n",
    "model.add(Convolution2D(64, 3, 3, init='normal'))\n",
    "model.add(Activation('elu'))\n",
    "#model.add(BatchNormalization())\n",
    "\n",
    "# Layer 5: Input: 72 x 288 x 3 - Output: 35 x 143 x 24\n",
    "model.add(Convolution2D(64, 3, 3, init='normal'))\n",
    "model.add(Activation('elu'))\n",
    "#model.add(BatchNormalization())\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(100, init='normal'))\n",
    "model.add(Dropout(p=0.5))\n",
    "model.add(Activation('elu'))\n",
    "\n",
    "model.add(Dense(50, init='normal'))\n",
    "model.add(Dropout(p=0.5))\n",
    "model.add(Activation('elu'))\n",
    "\n",
    "model.add(Dense(10, init='normal'))\n",
    "model.add(Dropout(p=0.5))\n",
    "model.add(Activation('elu'))\n",
    "\n",
    "model.add(Dense(1, init='normal'))\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set = 6434\n",
      "Validation set = 1609\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Shuffle list\n",
    "list_images = shuffle(list_images)\n",
    "\n",
    "# Split testing set\n",
    "train_set, valid_set = train_test_split(list_images, test_size=0.2, random_state=0)\n",
    "\n",
    "print(\"Train set =\", len(train_set))\n",
    "print(\"Validation set =\", len(valid_set))\n",
    "\n",
    "# # Shuffle list\n",
    "# X, y = shuffle(X, y)\n",
    "\n",
    "# # Split testing set\n",
    "# X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# print(\"X_train shape =\", X_train.shape)\n",
    "# print(\"y_train shape =\", y_train.shape)\n",
    "# print(\"X_valid shape =\", X_valid.shape)\n",
    "# print(\"y_valid shape =\", y_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# histogram = y_train\n",
    "\n",
    "# plt.hist(histogram, 100, facecolor='blue');\n",
    "# plt.xlabel('Steering angle');\n",
    "# plt.ylabel('Frequency');\n",
    "# plt.title('Histogram of recorded steering angles');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bias = 0.3\n",
    "histogram = list()\n",
    "for steering in y_train:\n",
    "    steering_thresh = np.random.rand()\n",
    "    if (abs(steering) + bias) > steering_thresh:   \n",
    "        histogram.append(steering[0])\n",
    "\n",
    "plt.hist(histogram, 100, facecolor='blue');\n",
    "plt.xlabel('Steering angle');\n",
    "plt.ylabel('Frequency');\n",
    "plt.title('Histogram of recorded steering angles');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def myGenerator(X, y, batch_size, flag=\"test\"):\n",
    "    while 1:\n",
    "        X, y = shuffle(X, y)\n",
    "\n",
    "        for batch_ind in range(0, len(X), batch_size):\n",
    "\n",
    "            X_batch = np.empty(shape = [1, 288, 72, 3], dtype = np.uint8)\n",
    "            y_batch = np.empty(shape = [1], dtype = np.float32)\n",
    "\n",
    "            for i in range(batch_ind, min(batch_ind + batch_size, len(X))):\n",
    "\n",
    "                image = X[i]\n",
    "                steering = y[i]\n",
    "\n",
    "                if (flag == \"test\"):\n",
    "                    image, steering = brightness_image(np.copy(image), steering)\n",
    "                    image, steering = rotate_image(np.copy(image), steering)\n",
    "                    image, steering = translate_image(np.copy(image), steering)\n",
    "                    \n",
    "                image = cut_image(image)\n",
    "\n",
    "                image = (image - 128.0) / 128.0\n",
    "\n",
    "                X_batch = np.vstack([X_batch, np.reshape(image, [1, 288, 72, 3])])\n",
    "                y_batch = np.vstack([y_batch, steering])\n",
    "\n",
    "            # Get rid of the first empty row\n",
    "            X_batch = X_batch[1:, :, :, :]\n",
    "            y_batch = y_batch[1:]\n",
    "\n",
    "            yield (X_batch, y_batch)\n",
    "            \n",
    "def myGenerator2(list, batch_size, flag=\"test\"):\n",
    "    while 1:\n",
    "        list = shuffle(list)\n",
    "\n",
    "        X_batch = np.empty(shape = [1, 64, 64, 3], dtype = np.uint8)\n",
    "        y_batch = np.empty(shape = [1], dtype = np.float32)\n",
    "        \n",
    "        X, y = load_data_batch(list, random.sample(range(len(list)), batch_size))\n",
    "\n",
    "        for i in range(len(X)):\n",
    "\n",
    "            image = X[i]\n",
    "            steering = y[i]\n",
    "\n",
    "            if (flag == \"test\"):\n",
    "                image, steering = brightness_image(np.copy(image), steering)\n",
    "                image, steering = rotate_image(np.copy(image), steering)\n",
    "                image, steering = translate_image(np.copy(image), steering)\n",
    "                image, steering = flip_image(np.copy(image), steering)\n",
    "\n",
    "            image = cut_image(image)\n",
    "\n",
    "            image = (image - 128.0) / 128.0\n",
    "\n",
    "            X_batch = np.vstack([X_batch, np.reshape(image, [1, 64, 64, 3])])\n",
    "            y_batch = np.vstack([y_batch, steering])\n",
    "\n",
    "        # Get rid of the first empty row\n",
    "        X_batch = X_batch[1:, :, :, :]\n",
    "        y_batch = y_batch[1:]\n",
    "\n",
    "        yield (X_batch, y_batch)\n",
    "# generator = myGenerator(X_valid, y_valid, 40)\n",
    "# a, b = next(generator)#generator.fit()\n",
    "# print(a.shape)\n",
    "# print(b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting model\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-7:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Ibis\\Anaconda3\\envs\\tensorflow-gpu\\lib\\threading.py\", line 914, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\Ibis\\Anaconda3\\envs\\tensorflow-gpu\\lib\\threading.py\", line 862, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"C:\\Users\\Ibis\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\engine\\training.py\", line 429, in data_generator_task\n",
      "    generator_output = next(self._generator)\n",
      "  File \"<ipython-input-8-b49802844c83>\", line 57, in myGenerator2\n",
      "    X_batch = np.vstack([X_batch, np.reshape(image, [1, 64, 64, 3])])\n",
      "  File \"C:\\Users\\Ibis\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\numpy\\core\\fromnumeric.py\", line 224, in reshape\n",
      "    return reshape(newshape, order=order)\n",
      "ValueError: total size of new array must be unchanged\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "output of generator should be a tuple (x, y, sample_weight) or (x, y). Found: None",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-0e4ec00c70d1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m                           \u001b[1;31m#callbacks=[model_checkpoint, learning_rate_plateau_reducer, early_stopping],\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                           \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmyGenerator2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalid_set\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"validation\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m                           nb_val_samples = 2000)\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[1;31m# fit = model.fit_generator(myGenerator(X_train, y_train, batch_size),\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Ibis\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, samples_per_epoch, nb_epoch, verbose, callbacks, validation_data, nb_val_samples, class_weight, max_q_size, nb_worker, pickle_safe, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    933\u001b[0m                                         \u001b[0mnb_worker\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnb_worker\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    934\u001b[0m                                         \u001b[0mpickle_safe\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpickle_safe\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 935\u001b[0;31m                                         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m    936\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    937\u001b[0m     def evaluate_generator(self, generator, val_samples,\n",
      "\u001b[0;32mC:\\Users\\Ibis\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, samples_per_epoch, nb_epoch, verbose, callbacks, validation_data, nb_val_samples, class_weight, max_q_size, nb_worker, pickle_safe, initial_epoch)\u001b[0m\n\u001b[1;32m   1526\u001b[0m                                          \u001b[1;34m'(x, y, sample_weight) '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1527\u001b[0m                                          \u001b[1;34m'or (x, y). Found: '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1528\u001b[0;31m                                          str(generator_output))\n\u001b[0m\u001b[1;32m   1529\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1530\u001b[0m                         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgenerator_output\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: output of generator should be a tuple (x, y, sample_weight) or (x, y). Found: None"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "# compile and fit model\n",
    "print(\"Fitting model\")\n",
    "model.compile(loss='mse', metrics=['mse'], optimizer=Adam(lr=0.001))\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', min_delta=0.00001, patience=2, verbose=1)\n",
    "model_checkpoint = ModelCheckpoint(filepath='model.weights.{epoch:02d}-{val_loss:.5f}.h5', verbose=1, save_best_only=True, save_weights_only=True)\n",
    "learning_rate_plateau_reducer = ReduceLROnPlateau(verbose=1, patience=0, epsilon=1e-5)\n",
    "\n",
    "batch_size=40\n",
    "\n",
    "fit = model.fit_generator(myGenerator2(train_set, batch_size),\n",
    "                          verbose=1, samples_per_epoch=2000,\n",
    "                          nb_epoch=5,\n",
    "                          #callbacks=[model_checkpoint, learning_rate_plateau_reducer, early_stopping],\n",
    "                          validation_data=myGenerator2(valid_set, batch_size, \"validation\"),\n",
    "                          nb_val_samples = 2000)\n",
    "\n",
    "# fit = model.fit_generator(myGenerator(X_train, y_train, batch_size),\n",
    "#                           verbose=1, samples_per_epoch=len(X_train),\n",
    "#                           nb_epoch=5,\n",
    "#                           #callbacks=[model_checkpoint, learning_rate_plateau_reducer, early_stopping],\n",
    "#                           validation_data=myGenerator(X_valid, y_valid, batch_size, \"validation\"),\n",
    "#                           nb_val_samples = len(X_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# scores = model.evaluate(myGenerator(X_valid, y_valid, batch_size, \"validation\"), verbose=0)\n",
    "# print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "\n",
    "# compare model predicted steering angles with labeled values\n",
    "# y_train_predict = model.predict(X_train)\n",
    "# print(y_train_predict.shape)\n",
    "\n",
    "# evaluate the model\n",
    "# np.set_printoptions(suppress=True)\n",
    "# print(y_train_predict[0:40].T)\n",
    "# print(y_train[0:40].T)\n",
    "\n",
    "# output model\n",
    "print(\"Saving model structure and weights\")\n",
    "model_json = model.to_json()\n",
    "import json\n",
    "with open ('model.json', 'w') as f:\n",
    "    json.dump(model_json, f, indent=4, sort_keys=True, separators=(',', ':'))\n",
    "\n",
    "model.save_weights('model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Not using anymore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# fit = model.fit(X_train, y_train, nb_epoch=10, batch_size=40, validation_data=(X_valid, y_valid), callbacks=[model_checkpoint, learning_rate_plateau_reducer, early_stopping])\n",
    "\n",
    "#  samples_per_epoch=1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def load_data(list_images):\n",
    "#     # Placeholders for the images and labels from web\n",
    "#     X_train = np.empty(shape = [1, 320, 160, 3], dtype = np.uint8)\n",
    "#     y_train = np.empty(shape = [1], dtype = np.float32)\n",
    "#     i = 1\n",
    "\n",
    "#     for data in list_images:\n",
    "#         image = Image.open(\"data/\" + data[0])\n",
    "#         steering = data[1]\n",
    "\n",
    "#         X_train = np.vstack([X_train, np.reshape(image, [1, 320, 160, 3])])\n",
    "#         y_train = np.vstack([y_train, steering])\n",
    "        \n",
    "#         image, steering = flip_image(np.copy(image), steering)\n",
    "        \n",
    "#         X_train = np.vstack([X_train, np.reshape(image, [1, 320, 160, 3])])\n",
    "#         y_train = np.vstack([y_train, steering])\n",
    "        \n",
    "#         i += 1\n",
    "#         print(str(i) + \"/\" + str(len(list_images)))\n",
    "    \n",
    "#     # Get rid of the first empty row\n",
    "#     X_train = X_train[1:, :, :, :]\n",
    "#     y_train = y_train[1:]\n",
    "\n",
    "#     return X_train, y_train\n",
    "\n",
    "# def load_data_valid(list_images):\n",
    "#     # Placeholders for the images and labels from web\n",
    "#     X_train = np.empty(shape = [1, 288, 72, 3], dtype = np.uint8)\n",
    "#     y_train = np.empty(shape = [1], dtype = np.float32)\n",
    "    \n",
    "#     i = 0\n",
    "    \n",
    "#     for data in list_images:\n",
    "#         image = Image.open(\"data/\" + data[0])\n",
    "#         steering = data[1]\n",
    "\n",
    "#         image = cut_image(np.copy(image))\n",
    "\n",
    "#         image = (image - 128.0) / 128.0\n",
    "        \n",
    "#         X_train = np.vstack([X_train, np.reshape(image, [1, 288, 72, 3])])\n",
    "#         y_train = np.vstack([y_train, steering])\n",
    "        \n",
    "#         image, steering = flip_image(np.copy(image), steering)\n",
    "        \n",
    "#         X_train = np.vstack([X_train, np.reshape(image, [1, 288, 72, 3])])\n",
    "#         y_train = np.vstack([y_train, steering])\n",
    "        \n",
    "#         i += 1\n",
    "#         print(str(i) + \"/\" + str(len(list_images)))\n",
    "    \n",
    "    \n",
    "#     # Get rid of the first empty row\n",
    "#     X_train = X_train[1:, :, :, :]\n",
    "#     y_train = y_train[1:]\n",
    "\n",
    "#     return X_train, y_train\n",
    "\n",
    "# # from random import randint\n",
    "\n",
    "# # indices = random.sample(range(0, len(list_images)), 21)\n",
    "# # X_train, y_train = load_data(list_images, indices)\n",
    "# # #print(y_train)\n",
    "                \n",
    "# # # Plot an example of images processed\n",
    "# # fig = plt.figure(facecolor=\"white\");\n",
    "# # fig.set_size_inches(15, 4);\n",
    "# # fig.subplots_adjust(hspace=.5);\n",
    "\n",
    "# # for i in range(21):    \n",
    "# #     ax=fig.add_subplot(3, 7, i+1);    \n",
    "# #     ax.imshow(np.reshape(X_train[i], [72, 288, 3]), vmin=0, vmax=255);\n",
    "# #     ax.axis('off');\n",
    "# #     ax.set_title(\"Steering: {0:.2f}\".format(y_train[i][0]), fontsize = 10);\n",
    "# #     ax.axis('tight');\n",
    "# # plt.suptitle('Image examples with augmentation');"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

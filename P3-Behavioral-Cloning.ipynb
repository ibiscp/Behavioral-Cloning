{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters to adjust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "zero_band = 0.15 # 0.15\n",
    "translate = 0.002 # 0.002\n",
    "steering_coefficient = 0.15 # 0.15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Images File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "list_images = list()\n",
    "path = 'data'\n",
    "with open(path + '\\driving_log.csv', 'r') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    next(reader)\n",
    "    for row in reader:\n",
    "        center = row[0].strip()\n",
    "        left = row[1].strip()\n",
    "        right = row[2].strip()\n",
    "        steering = float(row[3])\n",
    "        throttle = float(row[4])\n",
    "        brake = float(row[5])\n",
    "        speed = float(row[6])\n",
    "\n",
    "        if steering == 0:\n",
    "            if (np.random.rand() <= zero_band):\n",
    "                list_images.append([center, left, right, steering, throttle, brake, speed])\n",
    "        else:\n",
    "            list_images.append([center, left, right, steering, throttle, brake, speed])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ploting histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xa100e44a90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "histogram = [x[3] for x in list_images]\n",
    "\n",
    "plt.hist(histogram, bins = 40, facecolor='blue', edgecolor = \"black\");\n",
    "plt.xlabel('Steering angle');\n",
    "plt.ylabel('Frequency');\n",
    "plt.title('Histogram of recorded steering angles');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "def flip_image(img, steering):\n",
    "    if random.randint(0, 1):\n",
    "        return cv2.flip(img, 1), -steering\n",
    "    else:\n",
    "        return img, steering\n",
    "\n",
    "def brightness_image(img, steering):\n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
    "    hsv[:,:,2] = hsv[:,:,2] * (1 + np.random.uniform(-0.6, 0.2))\n",
    "    return cv2.cvtColor(hsv, cv2.COLOR_HSV2RGB), steering\n",
    "\n",
    "def rotate_image(img, steering):\n",
    "    rows,cols,channel = img.shape\n",
    "    M = cv2.getRotationMatrix2D((cols/2,rows/2), random.uniform(-3, 3), 1)\n",
    "    return cv2.warpAffine(img,M,(cols,rows), borderMode=1), steering\n",
    "\n",
    "def crop_image(img):\n",
    "    return img[60:136, :, :]\n",
    "\n",
    "def translate_image(img, steering, horz_range=30, vert_range=5):\n",
    "    rows, cols, chs = img.shape\n",
    "    tx = np.random.randint(-horz_range, horz_range+1)\n",
    "    ty = np.random.randint(-vert_range, vert_range+1)\n",
    "    steering = steering + tx * translate\n",
    "    tr_M = np.float32([[1,0,tx], [0,1,ty]])\n",
    "    img = cv2.warpAffine(img, tr_M, (cols,rows), borderMode=1)\n",
    "    return img, steering\n",
    "\n",
    "def shadow_image(img, steering):\n",
    "    rows, cols, chs = img.shape\n",
    "    \n",
    "    # Generate a separate buffer\n",
    "    shadows = img.copy()\n",
    "\n",
    "    randomUp = int(random.random() * cols)\n",
    "    randomDown = int(random.random() * cols)\n",
    "    \n",
    "    if random.randint(0, 1):\n",
    "        poly = [[randomUp,0],[cols,0],[cols,rows], [randomDown,rows]]\n",
    "    else:\n",
    "        poly = [[randomUp,0],[0,0],[0,rows], [randomDown,0]]\n",
    "        \n",
    "    cv2.fillPoly(shadows, np.array([poly]), -1)\n",
    "\n",
    "    alpha = np.random.uniform(0.6, 0.9)\n",
    "    return cv2.addWeighted(shadows, alpha, img, 1-alpha,0,img), steering\n",
    "\n",
    "def shear_image(image, steering_angle, shear_range=200):\n",
    "    if random.randint(0, 1):\n",
    "        rows, cols, ch = image.shape\n",
    "        dx = np.random.randint(-shear_range, shear_range + 1)\n",
    "        random_point = [cols / 2 + dx, rows / 2]\n",
    "        pts1 = np.float32([[0, rows], [cols, rows], [cols / 2, rows / 2]])\n",
    "        pts2 = np.float32([[0, rows], [cols, rows], random_point])\n",
    "        dsteering = dx / (rows / 2) * 360 / (2 * np.pi * 25.0) / 6.0\n",
    "        M = cv2.getAffineTransform(pts1, pts2)\n",
    "        image = cv2.warpAffine(image, M, (cols, rows), borderMode=1)\n",
    "        steering_angle += dsteering\n",
    "\n",
    "    return image, steering_angle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural network implementation\n",
    "Bellow is implemented the CNN from [CommaAI](https://github.com/commaai/research/blob/master/train_steering_model.py) and [NVIDIA](https://arxiv.org/pdf/1604.07316v1.pdf) architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "lambda_1 (Lambda)                (None, 64, 64, 3)     0           lambda_input_1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_1 (Convolution2D)  (None, 32, 32, 24)    1824        lambda_1[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "activation_1 (Activation)        (None, 32, 32, 24)    0           convolution2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_1 (MaxPooling2D)    (None, 31, 31, 24)    0           activation_1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_2 (Convolution2D)  (None, 16, 16, 36)    21636       maxpooling2d_1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_2 (Activation)        (None, 16, 16, 36)    0           convolution2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_2 (MaxPooling2D)    (None, 15, 15, 36)    0           activation_2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_3 (Convolution2D)  (None, 8, 8, 48)      43248       maxpooling2d_2[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_3 (Activation)        (None, 8, 8, 48)      0           convolution2d_3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_3 (MaxPooling2D)    (None, 7, 7, 48)      0           activation_3[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_4 (Convolution2D)  (None, 7, 7, 64)      27712       maxpooling2d_3[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_4 (Activation)        (None, 7, 7, 64)      0           convolution2d_4[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_4 (MaxPooling2D)    (None, 6, 6, 64)      0           activation_4[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_5 (Convolution2D)  (None, 6, 6, 64)      36928       maxpooling2d_4[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_5 (Activation)        (None, 6, 6, 64)      0           convolution2d_5[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_5 (MaxPooling2D)    (None, 5, 5, 64)      0           activation_5[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (None, 1600)          0           maxpooling2d_5[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 1600)          0           flatten_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_6 (Activation)        (None, 1600)          0           dropout_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 1164)          1863564     activation_6[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)              (None, 1164)          0           dense_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "activation_7 (Activation)        (None, 1164)          0           dropout_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 100)           116500      activation_7[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)              (None, 100)           0           dense_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "activation_8 (Activation)        (None, 100)           0           dropout_3[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_3 (Dense)                  (None, 50)            5050        activation_8[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)              (None, 50)            0           dense_3[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "activation_9 (Activation)        (None, 50)            0           dropout_4[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_4 (Dense)                  (None, 10)            510         activation_9[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)              (None, 10)            0           dense_4[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "activation_10 (Activation)       (None, 10)            0           dropout_5[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_5 (Dense)                  (None, 1)             11          activation_10[0][0]              \n",
      "====================================================================================================\n",
      "Total params: 2,116,983\n",
      "Trainable params: 2,116,983\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Convolution2D, Flatten, Activation, MaxPooling2D, Dropout, Lambda, ELU\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.utils.visualize_util import plot\n",
    "\n",
    "# Input layer shape\n",
    "ch, row, col = 3, 64, 64\n",
    "\n",
    "def model_nv():\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Lambda(lambda x: x/127.5 - 1.,\n",
    "            input_shape=(col,row,ch),\n",
    "            output_shape=(col,row,ch)))\n",
    "    \n",
    "    model.add(Convolution2D(24, 5, 5, subsample=(2, 2), border_mode=\"same\"))\n",
    "    model.add(Activation('elu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(1, 1)))\n",
    "\n",
    "    model.add(Convolution2D(36, 5, 5, subsample=(2, 2), border_mode=\"same\"))\n",
    "    model.add(Activation('elu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(1, 1)))\n",
    "\n",
    "    model.add(Convolution2D(48, 5, 5, subsample=(2, 2), border_mode=\"same\"))\n",
    "    model.add(Activation('elu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(1, 1)))\n",
    "\n",
    "    model.add(Convolution2D(64, 3, 3, border_mode=\"same\"))\n",
    "    model.add(Activation('elu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(1, 1)))\n",
    "\n",
    "    model.add(Convolution2D(64, 3, 3, border_mode=\"same\"))\n",
    "    model.add(Activation('elu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(1, 1)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(.2))\n",
    "    model.add(Activation('elu'))\n",
    "    model.add(Dense(1164))\n",
    "    model.add(Dropout(.5))\n",
    "    model.add(Activation('elu'))\n",
    "    model.add(Dense(100))\n",
    "    model.add(Dropout(.5))\n",
    "    model.add(Activation('elu'))\n",
    "    model.add(Dense(50))\n",
    "    model.add(Dropout(.5))\n",
    "    model.add(Activation('elu'))\n",
    "    model.add(Dense(10))\n",
    "    model.add(Dropout(.5))\n",
    "    model.add(Activation('elu'))\n",
    "    model.add(Dense(1))\n",
    "    \n",
    "    plot(model, show_shapes=True, to_file='images/nv.png')\n",
    "    \n",
    "    return model\n",
    "\n",
    "def model_comma():\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Lambda(lambda x: x/127.5 - 1.,\n",
    "            input_shape=(col,row,ch),\n",
    "            output_shape=(col,row,ch)))\n",
    "    \n",
    "    model.add(Convolution2D(16, 8, 8, subsample=(4, 4), border_mode=\"same\"))\n",
    "    model.add(ELU())\n",
    "    \n",
    "    model.add(Convolution2D(32, 5, 5, subsample=(2, 2), border_mode=\"same\"))\n",
    "    model.add(ELU())\n",
    "    \n",
    "    model.add(Convolution2D(64, 5, 5, subsample=(2, 2), border_mode=\"same\"))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(.2))\n",
    "    model.add(ELU())\n",
    "    model.add(Dense(512))\n",
    "    model.add(Dropout(.5))\n",
    "    model.add(ELU())\n",
    "    model.add(Dense(1))\n",
    "    \n",
    "    plot(model, show_shapes=True, to_file='images/comma.png')\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = model_nv()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set = 3014\n",
      "Validation set = 1293\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Shuffle list\n",
    "list_images = shuffle(list_images)\n",
    "\n",
    "# Split testing set\n",
    "train_set, valid_set = train_test_split(list_images, test_size=0.3, random_state=0)\n",
    "\n",
    "print(\"Train set =\", len(train_set))\n",
    "print(\"Validation set =\", len(valid_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data\n",
    "Function to load the data given a list of images and the indices that need to be loaded. The data is only load to the memory when the generator asks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg\n",
    "\n",
    "def load_data_batch(data, indices):\n",
    "    # Placeholders for the images and labels from web\n",
    "    X = list()\n",
    "    y = list()\n",
    "\n",
    "    for i in indices:\n",
    "        rnd = np.random.randint(0, 3)\n",
    "        image = plt.imread(path + \"\\\\\" + data[i][rnd])\n",
    "        steering = data[i][3]\n",
    "        \n",
    "        if rnd == 1:\n",
    "            steering += steering_coefficient\n",
    "        elif rnd == 2:\n",
    "            steering -= steering_coefficient\n",
    "            \n",
    "        if abs(steering) > 1:\n",
    "            steering = -1 if (steering < 0) else 1\n",
    "\n",
    "        X.append(image)\n",
    "        y.append(steering)\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generator function\n",
    "Return the images and steering values needed to the batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def myGenerator(samples, batch_size, augment=True):\n",
    "    while True:\n",
    "        X_batch = []\n",
    "        y_batch = []\n",
    "        \n",
    "        indices = np.random.randint(0, len(samples), batch_size)\n",
    "        \n",
    "        X, y = load_data_batch(samples, indices)\n",
    "\n",
    "        for i in range(batch_size):\n",
    "            image = X[i]\n",
    "            angle = y[i]\n",
    "            \n",
    "            if augment:\n",
    "                image, angle = shear_image(image, angle)\n",
    "                image, angle = brightness_image(image, angle)\n",
    "                image, angle = translate_image(image, angle)\n",
    "                image, angle = rotate_image(image, angle)\n",
    "                image, angle = shadow_image(image, angle)\n",
    "                image, angle = flip_image(image, angle)\n",
    "            \n",
    "            image = crop_image(image)\n",
    "            image = cv2.resize(image,(64, 64), interpolation = cv2.INTER_AREA)\n",
    "\n",
    "            X_batch.append(image)\n",
    "            y_batch.append(angle)\n",
    "\n",
    "        yield np.array(X_batch), np.array(y_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural network training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      "Epoch 00000: val_loss improved from inf to 0.08446, saving model to model.weights.00-0.08446.h5\n",
      "183s - loss: 0.2219 - val_loss: 0.0845\n",
      "Epoch 2/7\n",
      "Epoch 00001: val_loss improved from 0.08446 to 0.05783, saving model to model.weights.01-0.05783.h5\n",
      "189s - loss: 0.1047 - val_loss: 0.0578\n",
      "Epoch 3/7\n",
      "Epoch 00002: val_loss improved from 0.05783 to 0.04495, saving model to model.weights.02-0.04495.h5\n",
      "185s - loss: 0.0863 - val_loss: 0.0450\n",
      "Epoch 4/7\n",
      "Epoch 00003: val_loss did not improve\n",
      "190s - loss: 0.0735 - val_loss: 0.0534\n",
      "Epoch 5/7\n",
      "Epoch 00004: val_loss did not improve\n",
      "186s - loss: 0.0671 - val_loss: 0.0473\n",
      "Epoch 6/7\n",
      "\n",
      "Epoch 00005: reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 00005: val_loss did not improve\n",
      "173s - loss: 0.0605 - val_loss: 0.0573\n",
      "Epoch 7/7\n",
      "Epoch 00006: val_loss improved from 0.04495 to 0.03921, saving model to model.weights.06-0.03921.h5\n",
      "180s - loss: 0.0553 - val_loss: 0.0392\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer=Adam(lr=1e-3))\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', min_delta=0.000001, patience=5, verbose=1)\n",
    "model_checkpoint = ModelCheckpoint(filepath='model.weights.{epoch:02d}-{val_loss:.5f}.h5', verbose=1, save_best_only=True, save_weights_only=True)\n",
    "learning_rate_plateau_reducer = ReduceLROnPlateau(verbose=1, patience=2, epsilon=1e-5)\n",
    "\n",
    "batch_size= 50\n",
    "samples_epoch_test = 20000\n",
    "samples_epoch_validation = 2000\n",
    "n_epoch = 7\n",
    "\n",
    "fit = model.fit_generator(myGenerator(train_set, batch_size),\n",
    "                          verbose=2, samples_per_epoch=samples_epoch_test,\n",
    "                          nb_epoch=n_epoch,\n",
    "                          callbacks=[learning_rate_plateau_reducer, early_stopping,model_checkpoint],\n",
    "                          validation_data=myGenerator(valid_set, batch_size),\n",
    "                          nb_val_samples = samples_epoch_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "model_json = model.to_json()\n",
    "with open ('model.json', 'w') as f:\n",
    "    json.dump(model_json, f, indent=4, sort_keys=True, separators=(',', ':'))\n",
    "\n",
    "model.save_weights('model.h5')\n",
    "\n",
    "print(\"Model Saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

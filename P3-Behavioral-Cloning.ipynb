{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters to adjust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bias = 0.10       # Bias for the input data (1 consider all)\n",
    "offset = 0.20     # Steering value to be added to the right and left cameras\n",
    "zero_band = 0.20  # Consider only 10% of the zero steering data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Images File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images mapped with 3030 examples\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "list_images = list()\n",
    "\n",
    "with open('data\\driving_log.csv', 'r') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    next(reader)\n",
    "    for row in reader:\n",
    "        steering = float(row[3])\n",
    "        throttle = float(row[4])\n",
    "        brake = float(row[5])\n",
    "        speed = float(row[6])\n",
    "\n",
    "        steering_thresh = np.random.rand()\n",
    "        if (abs(steering) + bias) < steering_thresh:\n",
    "            pass # drop sample\n",
    "        else:\n",
    "            if (steering == 0):\n",
    "                if (np.random.rand() < zero_band):\n",
    "                    # Center image\n",
    "                    list_images.append([row[0].replace(\" \", \"\"), steering, throttle, brake, speed])\n",
    "                    # Left image\n",
    "                    list_images.append([row[1].replace(\" \", \"\"), steering + offset, throttle, brake, speed])\n",
    "                    # Right image\n",
    "                    list_images.append([row[2].replace(\" \", \"\"), steering - offset, throttle, brake, speed])\n",
    "            else:\n",
    "                # Center image\n",
    "                list_images.append([row[0].replace(\" \", \"\"), steering, throttle, brake, speed])\n",
    "                # Left image\n",
    "                list_images.append([row[1].replace(\" \", \"\"), steering + offset, throttle, brake, speed])\n",
    "                # Right image\n",
    "                list_images.append([row[2].replace(\" \", \"\"), steering - offset, throttle, brake, speed])\n",
    "\n",
    "print('Images mapped with {} examples'.format(len(list_images)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ploting histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x476c6b3470>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "histogram = [x[1] for x in list_images]\n",
    "\n",
    "plt.hist(histogram, bins = 40, facecolor='blue', range=[-1, 1], histtype='bar');\n",
    "plt.xlabel('Steering angle');\n",
    "plt.ylabel('Frequency');\n",
    "plt.title('Histogram of recorded steering angles');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "def flip_image(img, steering):\n",
    "    if random.randint(0, 1):\n",
    "        return cv2.flip(img, 1), -steering\n",
    "    else:\n",
    "        return img, steering\n",
    "\n",
    "def brightness_image(img, steering):\n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    hsv[:,:,2] = hsv[:,:,2] * random.uniform(0.3, 1.2)\n",
    "    return cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR), steering\n",
    "\n",
    "def rotate_image(img, steering):\n",
    "    rows,cols,channel = img.shape\n",
    "    M = cv2.getRotationMatrix2D((cols/2,rows/2), random.uniform(-5, 5), 1)\n",
    "    return cv2.warpAffine(img,M,(cols,rows)), steering\n",
    "\n",
    "def cut_image(img):\n",
    "    rows,cols,channel = img.shape\n",
    "    top = int(.4 * rows)\n",
    "    botton = int(.85 * rows)\n",
    "    border = int(.05 * cols)\n",
    "    return img[top:botton, border:cols-border, :]\n",
    "\n",
    "def translate_image(img, steering, horz_range=30, vert_range=5):\n",
    "    rows, cols, chs = img.shape\n",
    "    tx = np.random.randint(-horz_range, horz_range+1)\n",
    "    ty = np.random.randint(-vert_range, vert_range+1)\n",
    "    steering = steering + tx * 0.0025 # mul by steering angle units per pixel\n",
    "    tr_M = np.float32([[1,0,tx], [0,1,ty]])\n",
    "    img = cv2.warpAffine(img, tr_M, (cols,rows), borderMode=1)\n",
    "    return img, steering\n",
    "\n",
    "def shadow_image(img, steering):\n",
    "    rows, cols, chs = img.shape\n",
    "    \n",
    "    # Generate a separate buffer\n",
    "    shadows = img.copy()\n",
    "\n",
    "    randomUp = int(random.random() * cols)\n",
    "    randomDown = int(random.random() * cols)\n",
    "    \n",
    "    if random.randint(0, 1):\n",
    "        poly = [[randomUp,0],[cols,0],[cols,rows], [randomDown,rows]]\n",
    "    else:\n",
    "        poly = [[randomUp,0],[0,0],[0,rows], [randomDown,0]]\n",
    "        \n",
    "    cv2.fillPoly(shadows, np.array([poly]), -1)\n",
    "\n",
    "    alpha = np.random.uniform(0.6, 0.9)\n",
    "    return cv2.addWeighted(shadows, alpha, img, 1-alpha,0,img), steering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data\n",
    "Function to load the data given a list of images and the indices that need to be loaded. The data is only load to the memory when the generator asks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_data_batch(list_images, indices):\n",
    "    # Placeholders for the images and labels from web\n",
    "    X = np.empty(shape = [1, 320, 160, 3], dtype = np.uint8)\n",
    "    y = np.empty(shape = [1], dtype = np.float32)\n",
    "\n",
    "    for i in indices:\n",
    "        image = Image.open(\"data/\" + list_images[i][0])\n",
    "        steering = list_images[i][1]\n",
    "\n",
    "        X = np.vstack([X, np.reshape(image, [1, 320, 160, 3])])\n",
    "        y = np.vstack([y, steering])\n",
    "\n",
    "    # Get rid of the first empty row\n",
    "    X = X[1:, :, :, :]\n",
    "    y = y[1:]\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural network implementation\n",
    "Bellow will be implemented the network, which is based on [CommaAI](https://github.com/commaai/research/blob/master/train_steering_model.py) algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "lambda_1 (Lambda)                (None, 64, 64, 3)     0           lambda_input_1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_1 (Convolution2D)  (None, 62, 62, 16)    448         lambda_1[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "activation_1 (Activation)        (None, 62, 62, 16)    0           convolution2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_1 (MaxPooling2D)    (None, 31, 31, 16)    0           activation_1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_2 (Convolution2D)  (None, 29, 29, 32)    4640        maxpooling2d_1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_2 (Activation)        (None, 29, 29, 32)    0           convolution2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_2 (MaxPooling2D)    (None, 9, 9, 32)      0           activation_2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_3 (Convolution2D)  (None, 7, 7, 48)      13872       maxpooling2d_2[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_3 (Activation)        (None, 7, 7, 48)      0           convolution2d_3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_3 (MaxPooling2D)    (None, 3, 3, 48)      0           activation_3[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (None, 432)           0           maxpooling2d_3[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 432)           0           flatten_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 256)           110848      dropout_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_4 (Activation)        (None, 256)           0           dense_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)              (None, 256)           0           activation_4[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 128)           32896       dropout_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_5 (Activation)        (None, 128)           0           dense_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_3 (Dense)                  (None, 16)            2064        activation_5[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "activation_6 (Activation)        (None, 16)            0           dense_3[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_4 (Dense)                  (None, 1)             17          activation_6[0][0]               \n",
      "====================================================================================================\n",
      "Total params: 164,785\n",
      "Trainable params: 164,785\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Convolution2D, Flatten, Activation, MaxPooling2D, Dropout, Lambda\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "model_height = 64\n",
    "model_weight = 64\n",
    "\n",
    "init = 'normal'\n",
    "input_shape=(model_height, model_weight, 3)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Lambda(lambda x: x/255.-0.5, input_shape=input_shape))\n",
    "\n",
    "model.add(Convolution2D(16, 3, 3, border_mode='valid', init=init))\n",
    "model.add(Activation('elu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Convolution2D(32, 3, 3, border_mode='valid', init=init))\n",
    "model.add(Activation('elu'))\n",
    "model.add(MaxPooling2D(pool_size=(3,3)))\n",
    "\n",
    "model.add(Convolution2D(48, 3, 3, border_mode='valid', init=init))\n",
    "model.add(Activation('elu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(256, init=init))\n",
    "model.add(Activation('elu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(128, init=init))\n",
    "model.add(Activation('elu'))\n",
    "\n",
    "model.add(Dense(16, init=init))\n",
    "model.add(Activation('elu'))\n",
    "\n",
    "model.add(Dense(1, init=init))\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set = 2424\n",
      "Validation set = 606\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Shuffle list\n",
    "list_images = shuffle(list_images)\n",
    "\n",
    "# Split testing set\n",
    "train_set, valid_set = train_test_split(list_images, test_size=0.2, random_state=0)\n",
    "\n",
    "print(\"Train set =\", len(train_set))\n",
    "print(\"Validation set =\", len(valid_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generator function\n",
    "Return the images and steering values needed to the batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def myGenerator(list, batch_size, samples_epoch, flag=\"test\"):\n",
    "    while 1:\n",
    "        list = shuffle(list)\n",
    "\n",
    "        indices = random.sample(range(len(list)), batch_size)\n",
    "\n",
    "        X_batch = np.empty(shape = [1, model_height, model_weight, 3], dtype = np.uint8)\n",
    "        y_batch = np.empty(shape = [1], dtype = np.float32)\n",
    "\n",
    "        X, y = load_data_batch(list, indices)\n",
    "\n",
    "        for i in range(0, batch_size):\n",
    "\n",
    "            image = X[i]\n",
    "            steering = y[i]\n",
    "\n",
    "            if (flag == \"test\"):\n",
    "                image, steering = brightness_image(np.copy(image), steering)\n",
    "                image, steering = rotate_image(np.copy(image), steering)\n",
    "                image, steering = translate_image(np.copy(image), steering)\n",
    "                image, steering = shadow_image(np.copy(image), steering)\n",
    "                image, steering = flip_image(np.copy(image), steering)\n",
    "\n",
    "            image = cut_image(image)\n",
    "\n",
    "            image = cv2.resize(image,(model_height, model_height), interpolation = cv2.INTER_CUBIC)\n",
    "\n",
    "            X_batch = np.vstack([X_batch, np.reshape(image, [1, model_height, model_weight, 3])])\n",
    "            y_batch = np.vstack([y_batch, steering])\n",
    "\n",
    "        # Get rid of the first empty row\n",
    "        X_batch = X_batch[1:, :, :, :]\n",
    "        y_batch = y_batch[1:]\n",
    "\n",
    "        yield (X_batch, y_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural network training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting model\n",
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 257s - loss: 0.0945 - mean_squared_error: 0.0945 - val_loss: 0.0772 - val_mean_squared_error: 0.0772\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 2/10\n",
      "1024/4096 [======>.......................] - ETA: 12s - loss: 0.0888 - mean_squared_error: 0.0888\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "# compile and fit model\n",
    "print(\"Fitting model\")\n",
    "\n",
    "model.compile(loss='mse', metrics=['mse'], optimizer=Adam(lr=0.001))\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', min_delta=0.00001, patience=3, verbose=1)\n",
    "#model_checkpoint = ModelCheckpoint(filepath='model.weights.{epoch:02d}-{val_loss:.5f}.h5', verbose=1, save_best_only=True, save_weights_only=True)\n",
    "learning_rate_plateau_reducer = ReduceLROnPlateau(verbose=1, patience=2, epsilon=1e-5)\n",
    "\n",
    "batch_size=2**9\n",
    "samples_epoch_test = 2**12\n",
    "samples_epoch_validation = 2**10\n",
    "n_epoch = 10\n",
    "\n",
    "fit = model.fit_generator(myGenerator(train_set, batch_size, samples_epoch_test),\n",
    "                          verbose=1, samples_per_epoch=samples_epoch_test,\n",
    "                          nb_epoch=n_epoch,\n",
    "                          callbacks=[learning_rate_plateau_reducer, early_stopping],\n",
    "                          validation_data=myGenerator(valid_set, batch_size, samples_epoch_validation, \"validation\"),\n",
    "                          nb_val_samples = samples_epoch_validation)\n",
    "\n",
    "# output model\n",
    "print(\"Saving model structure and weights\")\n",
    "model_json = model.to_json()\n",
    "import json\n",
    "with open ('model.json', 'w') as f:\n",
    "    json.dump(model_json, f, indent=4, sort_keys=True, separators=(',', ':'))\n",
    "\n",
    "model.save_weights('model.h5')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

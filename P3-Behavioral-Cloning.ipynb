{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters to adjust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "zero_band = 0.14 # 0.15\n",
    "translate = 0.0015 # 0.0015\n",
    "steering_coefficient = 0.06 # 0.07"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Images File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "list_images = list()\n",
    "path = 'data'\n",
    "with open(path + '\\driving_log.csv', 'r') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    next(reader)\n",
    "    for row in reader:\n",
    "        center = row[0].strip()\n",
    "        left = row[1].strip()\n",
    "        right = row[2].strip()\n",
    "        steering = float(row[3])\n",
    "        throttle = float(row[4])\n",
    "        brake = float(row[5])\n",
    "        speed = float(row[6])\n",
    "\n",
    "        if steering == 0:\n",
    "            if (np.random.rand() <= zero_band):\n",
    "                list_images.append([center, left, right, steering, throttle, brake, speed])\n",
    "        else:\n",
    "            list_images.append([center, left, right, steering, throttle, brake, speed])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ploting histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xae74f98e80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "histogram = [x[3] for x in list_images]\n",
    "\n",
    "plt.hist(histogram, bins = 40, facecolor='blue', edgecolor = \"black\");\n",
    "plt.xlabel('Steering angle');\n",
    "plt.ylabel('Frequency');\n",
    "plt.title('Histogram of recorded steering angles');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "def flip_image(img, steering):\n",
    "    if random.randint(0, 1):\n",
    "        return cv2.flip(img, 1), -steering\n",
    "    else:\n",
    "        return img, steering\n",
    "\n",
    "def brightness_image(img, steering):\n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
    "    hsv[:,:,2] = hsv[:,:,2] * (1 + np.random.uniform(-0.6, 0.2))\n",
    "    return cv2.cvtColor(hsv, cv2.COLOR_HSV2RGB), steering\n",
    "\n",
    "def rotate_image(img, steering):\n",
    "    rows,cols,channel = img.shape\n",
    "    M = cv2.getRotationMatrix2D((cols/2,rows/2), random.uniform(-3, 3), 1)\n",
    "    return cv2.warpAffine(img,M,(cols,rows), borderMode=1), steering\n",
    "\n",
    "def crop_image(img):\n",
    "    return img[60:136, :, :]\n",
    "\n",
    "def translate_image(img, steering, horz_range=30, vert_range=5):\n",
    "    rows, cols, chs = img.shape\n",
    "    tx = np.random.randint(-horz_range, horz_range+1)\n",
    "    ty = np.random.randint(-vert_range, vert_range+1)\n",
    "    steering = steering + tx * translate\n",
    "    tr_M = np.float32([[1,0,tx], [0,1,ty]])\n",
    "    img = cv2.warpAffine(img, tr_M, (cols,rows), borderMode=1)\n",
    "    return img, steering\n",
    "\n",
    "def shadow_image(img, steering):\n",
    "    rows, cols, chs = img.shape\n",
    "    \n",
    "    # Generate a separate buffer\n",
    "    shadows = img.copy()\n",
    "\n",
    "    randomUp = int(random.random() * cols)\n",
    "    randomDown = int(random.random() * cols)\n",
    "    \n",
    "    if random.randint(0, 1):\n",
    "        poly = [[randomUp,0],[cols,0],[cols,rows], [randomDown,rows]]\n",
    "    else:\n",
    "        poly = [[randomUp,0],[0,0],[0,rows], [randomDown,0]]\n",
    "        \n",
    "    cv2.fillPoly(shadows, np.array([poly]), -1)\n",
    "\n",
    "    alpha = np.random.uniform(0.6, 0.9)\n",
    "    return cv2.addWeighted(shadows, alpha, img, 1-alpha,0,img), steering\n",
    "\n",
    "def shear_image(image, steering_angle, shear_range=200):\n",
    "    if random.randint(0, 1):\n",
    "        rows, cols, ch = image.shape\n",
    "        dx = np.random.randint(-shear_range, shear_range + 1)\n",
    "        random_point = [cols / 2 + dx, rows / 2]\n",
    "        pts1 = np.float32([[0, rows], [cols, rows], [cols / 2, rows / 2]])\n",
    "        pts2 = np.float32([[0, rows], [cols, rows], random_point])\n",
    "        dsteering = dx / (rows / 2) * 360 / (2 * np.pi * 25.0) / 6.0\n",
    "        M = cv2.getAffineTransform(pts1, pts2)\n",
    "        image = cv2.warpAffine(image, M, (cols, rows), borderMode=1)\n",
    "        steering_angle += dsteering\n",
    "\n",
    "    return image, steering_angle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural network implementation\n",
    "Bellow is implemented the CNN from [CommaAI](https://github.com/commaai/research/blob/master/train_steering_model.py) and [NVIDIA](https://arxiv.org/pdf/1604.07316v1.pdf) architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "lambda_1 (Lambda)                (None, 64, 64, 3)     0           lambda_input_1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_1 (Convolution2D)  (None, 16, 16, 16)    3088        lambda_1[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "elu_1 (ELU)                      (None, 16, 16, 16)    0           convolution2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_2 (Convolution2D)  (None, 8, 8, 32)      12832       elu_1[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "elu_2 (ELU)                      (None, 8, 8, 32)      0           convolution2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_3 (Convolution2D)  (None, 4, 4, 64)      51264       elu_2[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (None, 1024)          0           convolution2d_3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 1024)          0           flatten_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "elu_3 (ELU)                      (None, 1024)          0           dropout_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 512)           524800      elu_3[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)              (None, 512)           0           dense_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "elu_4 (ELU)                      (None, 512)           0           dropout_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 1)             513         elu_4[0][0]                      \n",
      "====================================================================================================\n",
      "Total params: 592,497\n",
      "Trainable params: 592,497\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Convolution2D, Flatten, Activation, MaxPooling2D, Dropout, Lambda, ELU\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.utils.visualize_util import plot\n",
    "\n",
    "# Input layer shape\n",
    "ch, row, col = 3, 64, 64\n",
    "\n",
    "def model_nv():\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Lambda(lambda x: x/127.5 - 1.,\n",
    "            input_shape=(col,row,ch),\n",
    "            output_shape=(col,row,ch)))\n",
    "    \n",
    "    model.add(Convolution2D(24, 5, 5, subsample=(2, 2), border_mode=\"same\"))\n",
    "    model.add(Activation('elu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(1, 1)))\n",
    "\n",
    "    model.add(Convolution2D(36, 5, 5, subsample=(2, 2), border_mode=\"same\"))\n",
    "    model.add(Activation('elu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(1, 1)))\n",
    "\n",
    "    model.add(Convolution2D(48, 5, 5, subsample=(2, 2), border_mode=\"same\"))\n",
    "    model.add(Activation('elu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(1, 1)))\n",
    "\n",
    "    model.add(Convolution2D(64, 3, 3, border_mode=\"same\"))\n",
    "    model.add(Activation('elu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(1, 1)))\n",
    "\n",
    "    model.add(Convolution2D(64, 3, 3, border_mode=\"same\"))\n",
    "    model.add(Activation('elu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(1, 1)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(.2))\n",
    "    model.add(Activation('elu'))\n",
    "    model.add(Dense(1164))\n",
    "    model.add(Dropout(.5))\n",
    "    model.add(Activation('elu'))\n",
    "    model.add(Dense(100))\n",
    "    model.add(Dropout(.5))\n",
    "    model.add(Activation('elu'))\n",
    "    model.add(Dense(50))\n",
    "    model.add(Dropout(.5))\n",
    "    model.add(Activation('elu'))\n",
    "    model.add(Dense(10))\n",
    "    model.add(Dropout(.5))\n",
    "    model.add(Activation('elu'))\n",
    "    model.add(Dense(1))\n",
    "    \n",
    "    plot(model, show_shapes=True, to_file='images/nv.png')\n",
    "    \n",
    "    return model\n",
    "\n",
    "def model_comma():\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Lambda(lambda x: x/127.5 - 1.,\n",
    "            input_shape=(col,row,ch),\n",
    "            output_shape=(col,row,ch)))\n",
    "    \n",
    "    model.add(Convolution2D(16, 8, 8, subsample=(4, 4), border_mode=\"same\"))\n",
    "    model.add(ELU())\n",
    "    \n",
    "    model.add(Convolution2D(32, 5, 5, subsample=(2, 2), border_mode=\"same\"))\n",
    "    model.add(ELU())\n",
    "    \n",
    "    model.add(Convolution2D(64, 5, 5, subsample=(2, 2), border_mode=\"same\"))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(.2))\n",
    "    model.add(ELU())\n",
    "    model.add(Dense(512))\n",
    "    model.add(Dropout(.5))\n",
    "    model.add(ELU())\n",
    "    model.add(Dense(1))\n",
    "    \n",
    "    plot(model, show_shapes=True, to_file='images/comma.png')\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = model_comma()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set = 2972\n",
      "Validation set = 1275\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Shuffle list\n",
    "list_images = shuffle(list_images)\n",
    "\n",
    "# Split testing set\n",
    "train_set, valid_set = train_test_split(list_images, test_size=0.3, random_state=0)\n",
    "\n",
    "print(\"Train set =\", len(train_set))\n",
    "print(\"Validation set =\", len(valid_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data\n",
    "Function to load the data given a list of images and the indices that need to be loaded. The data is only load to the memory when the generator asks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg\n",
    "\n",
    "def load_data_batch(data, indices):\n",
    "    # Placeholders for the images and labels from web\n",
    "    X = list()\n",
    "    y = list()\n",
    "\n",
    "    for i in indices:\n",
    "        rnd = np.random.randint(0, 3)\n",
    "        image = plt.imread(path + \"\\\\\" + data[i][rnd])\n",
    "        steering = data[i][3]\n",
    "        \n",
    "        if rnd == 1:\n",
    "            steering += steering_coefficient\n",
    "        elif rnd == 2:\n",
    "            steering -= steering_coefficient\n",
    "            \n",
    "        if abs(steering) > 1:\n",
    "            steering = -1 if (steering < 0) else 1\n",
    "\n",
    "        X.append(image)\n",
    "        y.append(steering)\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generator function\n",
    "Return the images and steering values needed to the batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def myGenerator(samples, batch_size, augment=True):\n",
    "    while True:\n",
    "        X_batch = []\n",
    "        y_batch = []\n",
    "        \n",
    "        indices = np.random.randint(0, len(samples), batch_size)\n",
    "        \n",
    "        X, y = load_data_batch(samples, indices)\n",
    "\n",
    "        for i in range(batch_size):\n",
    "            image = X[i]\n",
    "            angle = y[i]\n",
    "            \n",
    "            if augment:\n",
    "                image, angle = shear_image(image, angle)\n",
    "                image, angle = brightness_image(image, angle)\n",
    "                image, angle = translate_image(image, angle)\n",
    "                image, angle = rotate_image(image, angle)\n",
    "                image, angle = shadow_image(image, angle)\n",
    "                image, angle = flip_image(image, angle)\n",
    "            \n",
    "            image = crop_image(image)\n",
    "            image = cv2.resize(image,(64, 64), interpolation = cv2.INTER_AREA)\n",
    "\n",
    "            X_batch.append(image)\n",
    "            y_batch.append(angle)\n",
    "\n",
    "        yield np.array(X_batch), np.array(y_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural network training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "138s - loss: 0.1675 - val_loss: 0.1408\n",
      "Epoch 2/20\n",
      "126s - loss: 0.1377 - val_loss: 0.1126\n",
      "Epoch 3/20\n",
      "124s - loss: 0.1132 - val_loss: 0.0989\n",
      "Epoch 4/20\n",
      "123s - loss: 0.0854 - val_loss: 0.0784\n",
      "Epoch 5/20\n",
      "123s - loss: 0.0648 - val_loss: 0.0681\n",
      "Epoch 6/20\n",
      "123s - loss: 0.0595 - val_loss: 0.0590\n",
      "Epoch 7/20\n",
      "123s - loss: 0.0526 - val_loss: 0.0801\n",
      "Epoch 8/20\n",
      "123s - loss: 0.0527 - val_loss: 0.0568\n",
      "Epoch 9/20\n",
      "123s - loss: 0.0495 - val_loss: 0.0798\n",
      "Epoch 10/20\n",
      "123s - loss: 0.0469 - val_loss: 0.0623\n",
      "Epoch 11/20\n",
      "\n",
      "Epoch 00010: reducing learning rate to 0.00010000000474974513.\n",
      "123s - loss: 0.0457 - val_loss: 0.0688\n",
      "Epoch 12/20\n",
      "124s - loss: 0.0361 - val_loss: 0.0536\n",
      "Epoch 13/20\n",
      "124s - loss: 0.0347 - val_loss: 0.0467\n",
      "Epoch 14/20\n",
      "123s - loss: 0.0349 - val_loss: 0.0444\n",
      "Epoch 15/20\n",
      "125s - loss: 0.0337 - val_loss: 0.0506\n",
      "Epoch 16/20\n",
      "123s - loss: 0.0323 - val_loss: 0.0524\n",
      "Epoch 17/20\n",
      "\n",
      "Epoch 00016: reducing learning rate to 1.0000000474974514e-05.\n",
      "123s - loss: 0.0319 - val_loss: 0.0498\n",
      "Epoch 18/20\n",
      "124s - loss: 0.0315 - val_loss: 0.0457\n",
      "Epoch 19/20\n",
      "\n",
      "Epoch 00018: reducing learning rate to 1.0000000656873453e-06.\n",
      "123s - loss: 0.0303 - val_loss: 0.0487\n",
      "Epoch 00018: early stopping\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer=Adam(lr=1e-3))\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', min_delta=0.000001, patience=4, verbose=1)\n",
    "model_checkpoint = ModelCheckpoint(filepath='model.weights.{epoch:02d}-{val_loss:.5f}.h5', verbose=1, save_best_only=True, save_weights_only=True)\n",
    "learning_rate_plateau_reducer = ReduceLROnPlateau(verbose=1, patience=2, epsilon=1e-5)\n",
    "\n",
    "batch_size= 50\n",
    "samples_epoch_test = 20000\n",
    "samples_epoch_validation = 2000\n",
    "n_epoch = 20\n",
    "\n",
    "fit = model.fit_generator(myGenerator(train_set, batch_size),\n",
    "                          verbose=2, samples_per_epoch=samples_epoch_test,\n",
    "                          nb_epoch=n_epoch,\n",
    "                          callbacks=[learning_rate_plateau_reducer, early_stopping],\n",
    "                          validation_data=myGenerator(valid_set, batch_size),\n",
    "                          nb_val_samples = samples_epoch_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "model_json = model.to_json()\n",
    "with open ('model.json', 'w') as f:\n",
    "    json.dump(model_json, f, indent=4, sort_keys=True, separators=(',', ':'))\n",
    "\n",
    "model.save_weights('model.h5')\n",
    "\n",
    "print(\"Model Saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

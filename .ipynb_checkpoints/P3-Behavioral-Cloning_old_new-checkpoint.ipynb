{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters to adjust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Bias for the input data (1 consider all)\n",
    "# Steering value to be added to the right and left cameras\n",
    "# Consider only 10% of the zero steering data\n",
    "\n",
    "bias = 1\n",
    "offset = 0.22\n",
    "zero_band = 0.15\n",
    "translate = 0.004\n",
    "\n",
    "# Funciona bem\n",
    "# bias = 0.3\n",
    "# offset = 0.25\n",
    "# zero_band = 0.05\n",
    "# translate = 0.004\n",
    "\n",
    "# Model 12\n",
    "# Working\n",
    "# bias = 1\n",
    "# offset = 0.20\n",
    "# zero_band = 0.10\n",
    "# translate = 0.003\n",
    "\n",
    "# Model 11\n",
    "# Best model\n",
    "# Track 2 - Success\n",
    "# bias = 1\n",
    "# offset = 0.20\n",
    "# zero_band = 0.10\n",
    "# translate = 0.003\n",
    "\n",
    "# Model 10\n",
    "# bias = 1\n",
    "# offset = 0.22\n",
    "# zero_band = 0.10\n",
    "# translate = 0.004\n",
    "\n",
    "# Model 9\n",
    "# Bad, getting worse\n",
    "# bias = 1\n",
    "# offset = 0.22\n",
    "# zero_band = 0.15\n",
    "# translate = 0.003\n",
    "\n",
    "# Model 8\n",
    "# bias = 1\n",
    "# offset = 0.22\n",
    "# zero_band = 0.15\n",
    "# translate = 0.003\n",
    "\n",
    "# Model 7\n",
    "# bias = 1\n",
    "# offset = 0.18\n",
    "# zero_band = 0.15\n",
    "# translate = 0.003\n",
    "\n",
    "# Model 6\n",
    "# Not good\n",
    "# bias = 0.6\n",
    "# offset = 0.25\n",
    "# zero_band = 0.15\n",
    "# translate = 0.003\n",
    "\n",
    "# Model 5\n",
    "# Showing less camera - not a good idea\n",
    "# bias = 1\n",
    "# offset = 0.25\n",
    "# zero_band = 0.15\n",
    "# translate = 0.004\n",
    "\n",
    "# Model 4\n",
    "# Showing sky - very bad\n",
    "# bias = 1\n",
    "# offset = 0.22\n",
    "# zero_band = 0.15\n",
    "# translate = 0.004\n",
    "\n",
    "# Model 3\n",
    "# BÃªbado\n",
    "# bias = 1\n",
    "# offset = 0.22\n",
    "# zero_band = 0.15\n",
    "# translate = 0.006\n",
    "\n",
    "# Model 2\n",
    "# Afraid of water\n",
    "# bias = 0.8\n",
    "# offset = 0.22\n",
    "# zero_band = 0.15\n",
    "# translate = 0.004\n",
    "\n",
    "## Model 1\n",
    "## Track 1 - Hitting the bridge\n",
    "## Track 2 - Success\n",
    "# bias = 1\n",
    "# offset = 0.22\n",
    "# zero_band = 0.15\n",
    "# translate = 0.004\n",
    "\n",
    "# bias = 1\n",
    "# offset = 0.22\n",
    "# zero_band = 0.15\n",
    "\n",
    "# bias = 0.60\n",
    "# offset = 0.20\n",
    "# zero_band = 0.25\n",
    "\n",
    "# bias = 0.10\n",
    "# offset = 0.20\n",
    "# zero_band = 0.20\n",
    "\n",
    "# bias = 1\n",
    "# offset = 0.20\n",
    "# zero_band = 0.20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Images File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images mapped with 12942 examples\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "\n",
    "list_images = list()\n",
    "path = 'data'\n",
    "with open(path + '\\driving_log.csv', 'r') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    next(reader)\n",
    "    for row in reader:\n",
    "        steering = float(row[3])\n",
    "        throttle = float(row[4])\n",
    "        brake = float(row[5])\n",
    "        speed = float(row[6])\n",
    "\n",
    "        steering_thresh = np.random.rand()\n",
    "        if (abs(steering) + bias) <= steering_thresh:\n",
    "            pass # drop sample\n",
    "        else:\n",
    "            if (steering == 0):\n",
    "                if (np.random.rand() <= zero_band):\n",
    "                    # Center image\n",
    "                    list_images.append([path + '\\\\' + row[0].strip(), steering, throttle, brake, speed])\n",
    "                    # Left image\n",
    "                    list_images.append([path + '\\\\' + row[1].strip(), steering + offset, throttle, brake, speed])\n",
    "                    # Right image\n",
    "                    list_images.append([path + '\\\\' + row[2].strip(), steering - offset, throttle, brake, speed])\n",
    "            else:\n",
    "                # Center image\n",
    "                list_images.append([path + '\\\\' + row[0].strip(), steering, throttle, brake, speed])\n",
    "                # Left image\n",
    "                list_images.append([path + '\\\\' + row[1].strip(), steering + offset, throttle, brake, speed])\n",
    "                # Right image\n",
    "                list_images.append([path + '\\\\' + row[2].strip(), steering - offset, throttle, brake, speed])\n",
    "\n",
    "# path = 'new_data'\n",
    "# with open(path + '\\driving_log.csv', 'r') as csvfile:\n",
    "#     reader = csv.reader(csvfile)\n",
    "#     for row in reader:\n",
    "#         steering = float(row[3])\n",
    "#         throttle = float(row[4])\n",
    "#         brake = float(row[5])\n",
    "#         speed = float(row[6])\n",
    "\n",
    "#         steering_thresh = np.random.rand()\n",
    "#         if (abs(steering) + bias) <= steering_thresh:\n",
    "#             pass # drop sample\n",
    "#         else:\n",
    "#             if (steering == 0):\n",
    "#                 if (np.random.rand() <= zero_band):\n",
    "#                     # Center image\n",
    "#                     head, tail = os.path.split(row[0])\n",
    "#                     list_images.append([path + '\\IMG\\\\' + tail, steering, throttle, brake, speed])\n",
    "#                     # Left image\n",
    "#                     head, tail = os.path.split(row[1])\n",
    "#                     list_images.append([path + '\\IMG\\\\' + tail, steering + offset, throttle, brake, speed])\n",
    "#                     # Right image\n",
    "#                     head, tail = os.path.split(row[2])\n",
    "#                     list_images.append([path + '\\IMG\\\\' + tail, steering - offset, throttle, brake, speed])\n",
    "#             else:\n",
    "#                 # Center image\n",
    "#                 head, tail = os.path.split(row[0])\n",
    "#                 list_images.append([path + '\\IMG\\\\' + tail, steering, throttle, brake, speed])\n",
    "#                 # Left image\n",
    "#                 head, tail = os.path.split(row[1])\n",
    "#                 list_images.append([path + '\\IMG\\\\' + tail, steering + offset, throttle, brake, speed])\n",
    "#                 # Right image\n",
    "#                 head, tail = os.path.split(row[2])\n",
    "#                 list_images.append([path + '\\IMG\\\\' + tail, steering - offset, throttle, brake, speed])\n",
    "                \n",
    "print('Images mapped with {} examples'.format(len(list_images)))\n",
    "#print(list_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ploting histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEWCAYAAABxMXBSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngIzqFQIEAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xf06c137e48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "histogram = [x[1] for x in list_images]\n",
    "\n",
    "plt.hist(histogram, bins = 40, facecolor='blue', range=[-1, 1], histtype='bar');\n",
    "plt.xlabel('Steering angle');\n",
    "plt.ylabel('Frequency');\n",
    "plt.title('Histogram of recorded steering angles');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data\n",
    "Function to load the data given a list of images and the indices that need to be loaded. The data is only load to the memory when the generator asks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg\n",
    "\n",
    "def load_data_batch(list_images, indices):\n",
    "    # Placeholders for the images and labels from web\n",
    "    X = np.empty(shape = [1, 320, 160, 3], dtype = np.uint8)\n",
    "    y = np.empty(shape = [1], dtype = np.float32)\n",
    "\n",
    "    for i in indices:\n",
    "        image = mpimg.imread(list_images[i][0])\n",
    "        steering = list_images[i][1]\n",
    "\n",
    "        X = np.vstack([X, np.reshape(image, [1, 320, 160, 3])])\n",
    "        y = np.vstack([y, steering])\n",
    "\n",
    "    # Get rid of the first empty row\n",
    "    X = X[1:, :, :, :]\n",
    "    y = y[1:]\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "def flip_image(img, steering):\n",
    "    if random.randint(0, 1):\n",
    "        return cv2.flip(img, 1), -steering\n",
    "    else:\n",
    "        return img, steering\n",
    "\n",
    "def brightness_image(img, steering):\n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
    "    hsv[:,:,2] = hsv[:,:,2] * random.uniform(0.3, 1.6)\n",
    "    return cv2.cvtColor(hsv, cv2.COLOR_HSV2RGB), steering\n",
    "\n",
    "def rotate_image(img, steering):\n",
    "    rows,cols,channel = img.shape\n",
    "    M = cv2.getRotationMatrix2D((cols/2,rows/2), random.uniform(-3, 3), 1)\n",
    "    return cv2.warpAffine(img,M,(cols,rows), borderMode=1), steering\n",
    "\n",
    "def cut_image(img):\n",
    "    return img[60:136, :, :]\n",
    "    #     rows,cols,_ = img.shape\n",
    "    #     top = int(.4 * rows)\n",
    "    #     botton = int(.85 * rows)\n",
    "    #     return img[top:botton, :, :]\n",
    "\n",
    "def translate_image(img, steering, horz_range=30, vert_range=5):\n",
    "    rows, cols, chs = img.shape\n",
    "    tx = np.random.randint(-horz_range, horz_range+1)\n",
    "    ty = np.random.randint(-vert_range, vert_range+1)\n",
    "    steering = steering + tx * translate # mul by steering angle units per pixel\n",
    "    tr_M = np.float32([[1,0,tx], [0,1,ty]])\n",
    "    img = cv2.warpAffine(img, tr_M, (cols,rows), borderMode=1)\n",
    "    return img, steering\n",
    "\n",
    "def shadow_image(img, steering):\n",
    "    rows, cols, chs = img.shape\n",
    "    \n",
    "    # Generate a separate buffer\n",
    "    shadows = img.copy()\n",
    "\n",
    "    randomUp = int(random.random() * cols)\n",
    "    randomDown = int(random.random() * cols)\n",
    "    \n",
    "    if random.randint(0, 1):\n",
    "        poly = [[randomUp,0],[cols,0],[cols,rows], [randomDown,rows]]\n",
    "    else:\n",
    "        poly = [[randomUp,0],[0,0],[0,rows], [randomDown,0]]\n",
    "        \n",
    "    cv2.fillPoly(shadows, np.array([poly]), -1)\n",
    "\n",
    "    alpha = np.random.uniform(0.6, 0.9)\n",
    "    return cv2.addWeighted(shadows, alpha, img, 1-alpha,0,img), steering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural network implementation\n",
    "Bellow will be implemented the CNN, which is based on [CommaAI](https://github.com/commaai/research/blob/master/train_steering_model.py) algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "lambda_1 (Lambda)                (None, 64, 64, 3)     0           lambda_input_1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_1 (Convolution2D)  (None, 62, 62, 16)    448         lambda_1[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "activation_1 (Activation)        (None, 62, 62, 16)    0           convolution2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_1 (MaxPooling2D)    (None, 31, 31, 16)    0           activation_1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_2 (Convolution2D)  (None, 29, 29, 32)    4640        maxpooling2d_1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_2 (Activation)        (None, 29, 29, 32)    0           convolution2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_2 (MaxPooling2D)    (None, 9, 9, 32)      0           activation_2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_3 (Convolution2D)  (None, 7, 7, 48)      13872       maxpooling2d_2[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_3 (Activation)        (None, 7, 7, 48)      0           convolution2d_3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_3 (MaxPooling2D)    (None, 3, 3, 48)      0           activation_3[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (None, 432)           0           maxpooling2d_3[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 432)           0           flatten_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 256)           110848      dropout_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_4 (Activation)        (None, 256)           0           dense_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)              (None, 256)           0           activation_4[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 128)           32896       dropout_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_5 (Activation)        (None, 128)           0           dense_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_3 (Dense)                  (None, 16)            2064        activation_5[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "activation_6 (Activation)        (None, 16)            0           dense_3[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_4 (Dense)                  (None, 1)             17          activation_6[0][0]               \n",
      "====================================================================================================\n",
      "Total params: 164,785\n",
      "Trainable params: 164,785\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Convolution2D, Flatten, Activation, MaxPooling2D, Dropout, Lambda\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "model_height = 64\n",
    "model_weight = 64\n",
    "\n",
    "init = 'normal'\n",
    "input_shape=(model_height, model_weight, 3)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Lambda(lambda x: x/255.-0.5, input_shape=input_shape))\n",
    "\n",
    "model.add(Convolution2D(16, 3, 3, border_mode='valid', init=init))\n",
    "model.add(Activation('elu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Convolution2D(32, 3, 3, border_mode='valid', init=init))\n",
    "model.add(Activation('elu'))\n",
    "model.add(MaxPooling2D(pool_size=(3,3)))\n",
    "\n",
    "model.add(Convolution2D(48, 3, 3, border_mode='valid', init=init))\n",
    "model.add(Activation('elu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(256, init=init))\n",
    "model.add(Activation('elu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(128, init=init))\n",
    "model.add(Activation('elu'))\n",
    "\n",
    "model.add(Dense(16, init=init))\n",
    "model.add(Activation('elu'))\n",
    "\n",
    "model.add(Dense(1, init=init))\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set = 10353\n",
      "Validation set = 2589\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Shuffle list\n",
    "list_images = shuffle(list_images)\n",
    "\n",
    "# Split testing set\n",
    "train_set, valid_set = train_test_split(list_images, test_size=0.2, random_state=0)\n",
    "\n",
    "print(\"Train set =\", len(train_set))\n",
    "print(\"Validation set =\", len(valid_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generator function\n",
    "Return the images and steering values needed to the batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def myGenerator(list, batch_size, samples_epoch, flag=\"test\"):\n",
    "    while 1:\n",
    "        #list = shuffle(list)\n",
    "\n",
    "        indices = random.sample(range(len(list)), batch_size)\n",
    "\n",
    "        X_batch = np.empty(shape = [1, model_height, model_weight, 3], dtype = np.uint8)\n",
    "        y_batch = np.empty(shape = [1], dtype = np.float32)\n",
    "\n",
    "        X, y = load_data_batch(list, indices)\n",
    "\n",
    "        for i in range(0, batch_size):\n",
    "\n",
    "            image = X[i]\n",
    "            steering = y[i]\n",
    "\n",
    "            if (flag == \"test\"):\n",
    "                #image, steering = brightness_image(image, steering)\n",
    "                image, steering = translate_image(image, steering)\n",
    "                image, steering = rotate_image(image, steering)\n",
    "                #image, steering = shadow_image(image, steering)\n",
    "                image, steering = flip_image(image, steering)\n",
    "            \n",
    "            image = cut_image(image)\n",
    "\n",
    "            image = cv2.resize(image,(model_height, model_height), interpolation = cv2.INTER_CUBIC)\n",
    "\n",
    "            X_batch = np.vstack([X_batch, np.reshape(image, [1, model_height, model_weight, 3])])\n",
    "            y_batch = np.vstack([y_batch, steering])\n",
    "\n",
    "        # Get rid of the first empty row\n",
    "        X_batch = X_batch[1:, :, :, :]\n",
    "        y_batch = y_batch[1:]\n",
    "\n",
    "        yield (X_batch, y_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural network training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "4900/5000 [============================>.] - ETA: 1s - loss: 0.0676 - mean_squared_error: 0.0676 \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\bEpoch 00000: val_loss improved from inf to 0.06026, saving model to model.weights.00-0.06026.h5\n",
      "5000/5000 [==============================] - 62s - loss: 0.0677 - mean_squared_error: 0.0677 - val_loss: 0.0603 - val_mean_squared_error: 0.0603\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "model.compile(loss='mse', metrics=['mse'], optimizer=Adam(lr=0.0001))\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', min_delta=0.000001, patience=5, verbose=1)\n",
    "model_checkpoint = ModelCheckpoint(filepath='model.weights.{epoch:02d}-{val_loss:.5f}.h5', verbose=1, save_best_only=True, save_weights_only=True)\n",
    "learning_rate_plateau_reducer = ReduceLROnPlateau(verbose=1, patience=2, epsilon=1e-5)\n",
    "\n",
    "batch_size=100\n",
    "samples_epoch_test = 5000\n",
    "samples_epoch_validation = 1000\n",
    "n_epoch = 1\n",
    "\n",
    "fit = model.fit_generator(myGenerator(train_set, batch_size, samples_epoch_test),\n",
    "                          verbose=1, samples_per_epoch=samples_epoch_test,\n",
    "                          nb_epoch=n_epoch,\n",
    "                          callbacks=[learning_rate_plateau_reducer, early_stopping,model_checkpoint],\n",
    "                          validation_data=myGenerator(valid_set, batch_size, samples_epoch_validation, \"validation\"),\n",
    "                          nb_val_samples = samples_epoch_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "model_json = model.to_json()\n",
    "with open ('model.json', 'w') as f:\n",
    "    json.dump(model_json, f, indent=4, sort_keys=True, separators=(',', ':'))\n",
    "\n",
    "model.save_weights('model.h5')\n",
    "\n",
    "print(\"Model Saved!\")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
